{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "947d7111-19ea-414c-aa5b-aa74beec2f05",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'flags' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 28\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# from state_tracking.utils import sgd_utils\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m _T5X_PREDICTIONS_JSONL \u001b[38;5;241m=\u001b[39m \u001b[43mflags\u001b[49m\u001b[38;5;241m.\u001b[39mDEFINE_string(\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt5x_predictions_jsonl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput JSONL file with T5X model predictions.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     31\u001b[0m _DSTC8_DATA_DIR \u001b[38;5;241m=\u001b[39m flags\u001b[38;5;241m.\u001b[39mDEFINE_string(\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdstc8_data_dir\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDirectory for the downloaded DSTC8 data, which contains \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe dialogue files and schema files of all datasets (train, dev, test)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     35\u001b[0m _OUTPUT_DIR \u001b[38;5;241m=\u001b[39m flags\u001b[38;5;241m.\u001b[39mDEFINE_string(\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_dir\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOutput directory for JSON-format model predictions for official DSTC8 \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevaluation.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'flags' is not defined"
     ]
    }
   ],
   "source": [
    "# Copyright 2021 Google Research.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "r\"\"\"Converts T5X predictions on SGD to DSTC8 official format for evaluation.\"\"\"\n",
    "\n",
    "import collections\n",
    "import enum\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import typing as tp\n",
    "import sgd_utils\n",
    "import attrs\n",
    "import tyro\n",
    "\n",
    "# from state_tracking.utils import sgd_utils\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "class AutoName(enum.Enum):\n",
    "    def _generate_next_value_(name, start, count, last_values):\n",
    "        return name\n",
    "\n",
    "\n",
    "class SplitEnum(AutoName):\n",
    "    train = enum.auto()\n",
    "    dev = enum.auto()\n",
    "    test = enum.auto()\n",
    "\n",
    "\n",
    "@attrs.define\n",
    "class ConvertSgdT5xSdtPredsConfig:\n",
    "    \"\"\"Configuration for converting T5X SDT preds to DSTC8.\n",
    "\n",
    "    Attributes:\n",
    "        t5x_predictions_jsonl (str): Input JSONL file with T5X model predictions.\n",
    "        dstc8_data_dir (str): Directory for the downloaded DSTC8 data, which contains\n",
    "            the dialogue files and schema files of all datasets (train, dev, test)\n",
    "        output_dir (str): Output directory for JSON-format model predictions for official DSTC8\n",
    "            evaluation.\n",
    "        dataset_split (str): Dataset split for evaluation. One of \"train\", \"dev\", \"test\".\n",
    "            Defaults to \"test\".\n",
    "        delimiter (str): Delimiter to separate slot/intent IDs from their descriptions or\n",
    "            values.\n",
    "    \"\"\"\n",
    "    t5x_predictions_jsonl: str\n",
    "    dstc8_data_dir: str\n",
    "    output_dir: str\n",
    "    dataset_split: SplitEnum = SplitEnum.test\n",
    "    delimiter: str = \"=\"\n",
    "    \n",
    "    \n",
    "\n",
    "_T5X_PREDICTIONS_JSONL = flags.DEFINE_string(\n",
    "    't5x_predictions_jsonl', None,\n",
    "    'Input JSONL file with T5X model predictions.')\n",
    "_DSTC8_DATA_DIR = flags.DEFINE_string(\n",
    "    'dstc8_data_dir', None,\n",
    "    'Directory for the downloaded DSTC8 data, which contains '\n",
    "    'the dialogue files and schema files of all datasets (train, dev, test)')\n",
    "_OUTPUT_DIR = flags.DEFINE_string(\n",
    "    'output_dir', None,\n",
    "    'Output directory for JSON-format model predictions for official DSTC8 '\n",
    "    'evaluation.')\n",
    "_DATASET_SPLIT = flags.DEFINE_enum('dataset_split', 'test',\n",
    "                                   ['train', 'dev', 'test'],\n",
    "                                   'Dataset split for evaluation.')\n",
    "_DELIMITER = flags.DEFINE_string(\n",
    "    'delimiter', '=', 'Delimiter to separate '\n",
    "    'slot/intent IDs from their descriptions or '\n",
    "    'values.')\n",
    "_EVALUATE_INTENT_ACC = flags.DEFINE_bool(\n",
    "    'evaluate_intent_acc', False, 'Whether to evaluate on active intent '\n",
    "    'classification task.')\n",
    "\n",
    "_SDT_CAT_SLOT_IDENTIFIER = 'of possible values'\n",
    "\n",
    "\n",
    "def _create_categorical_slot_to_value_map(\n",
    "    input_str: str) -> Dict[str, Dict[str, str]]:\n",
    "  \"\"\"Creates mappings from letters to values for categorical slots.\"\"\"\n",
    "  slot_values = input_str.split('[slots]')[1].split('[context]')[0].split(\n",
    "      '[intent]')[0].strip()\n",
    "  slot_to_option_to_value = collections.defaultdict(dict)\n",
    "  for slot, value in re.findall(\n",
    "      rf'(\\w+){_DELIMITER.value}(.*?)(?=\\w+{_DELIMITER.value}|$)', slot_values):\n",
    "    if _SDT_CAT_SLOT_IDENTIFIER not in value:\n",
    "      continue\n",
    "    options_str = value.split(_SDT_CAT_SLOT_IDENTIFIER)[1].strip()\n",
    "    for option, option_value in re.findall(r'([a-z])\\) (.*?)(?=[a-z]\\)|$)',\n",
    "                                           options_str):\n",
    "      slot_to_option_to_value[slot][option] = option_value.strip()\n",
    "\n",
    "  return slot_to_option_to_value\n",
    "\n",
    "\n",
    "def _create_intent_map(input_str: str) -> Dict[str, str]:\n",
    "  \"\"\"Creates mappings from letters to intent names.\"\"\"\n",
    "  intent_str = input_str.split('[intent]')[1].split('[context]')[0].strip()\n",
    "  intent_option_to_value = {}\n",
    "  if _SDT_CAT_SLOT_IDENTIFIER not in intent_str:\n",
    "    raise ValueError('Improperly formatted intent prompt: %s' % intent_str)\n",
    "  intent_str = intent_str.split(_SDT_CAT_SLOT_IDENTIFIER)[1].strip()\n",
    "  for option, option_value in re.findall(r'([a-z])\\) (.*?)(?=[a-z]\\)|$)',\n",
    "                                         intent_str):\n",
    "    intent_option_to_value[option] = option_value.strip()\n",
    "\n",
    "  return intent_option_to_value\n",
    "\n",
    "\n",
    "def _normalize_value_prediction(\n",
    "    slot_name: str, value: str,\n",
    "    slot_to_option_to_value: Dict[str, Dict[str, str]]) -> Optional[str]:\n",
    "  \"\"\"Normalizes a predicted value and maps a categorical option to value.\"\"\"\n",
    "  value = value.strip()\n",
    "  if value == 'none':\n",
    "    value = None\n",
    "\n",
    "  # Map decoded multiple choice letters back to actual value for cat slots.\n",
    "  elif slot_name in slot_to_option_to_value:\n",
    "    if value in slot_to_option_to_value[slot_name]:\n",
    "      value = slot_to_option_to_value[slot_name][value]\n",
    "    # Print cases where model didn't decode a valid multiple choice letter.\n",
    "    elif value != 'dontcare':\n",
    "      logging.info(\n",
    "          'Unexpected slot scenario. slot_name %s. value %s. '\n",
    "          'slot_to_option_to_value %s', slot_name, value,\n",
    "          slot_to_option_to_value)\n",
    "\n",
    "  return value\n",
    "\n",
    "\n",
    "def populate_json_predictions(\n",
    "    dialog_id_to_dialogue: Dict[str, sgd_utils.DialoguesDict],\n",
    "    frame_predictions: Dict[str, Union[str, Dict[str, str]]]) -> None:\n",
    "  \"\"\"Populates a dialogue JSON dictionary with frame-level T5X model outputs.\n",
    "\n",
    "  Given a single prediction from frame_predictions, this looks up the\n",
    "  corresponding frame from dialog_id_to_dialogue and modifies it in-place by\n",
    "  inserting the predictions into the dialogue state field.\n",
    "\n",
    "  Args:\n",
    "    dialog_id_to_dialogue: A mapping from dialog id to the dialogue json object\n",
    "    frame_predictions: A dict containing T5X predictions and example metadata\n",
    "  \"\"\"\n",
    "  preds = frame_predictions['prediction']\n",
    "  if not isinstance(preds, str):\n",
    "    raise ValueError(f\"'preds' must be string type, \"\n",
    "                     f'not {type(preds)}. preds: {preds}')\n",
    "  dialog_id = frame_predictions['input']['dialogue_id']\n",
    "  turn_id = int(frame_predictions['input']['turn_id'])\n",
    "  frame_id = int(frame_predictions['input']['frame_id'])\n",
    "\n",
    "  if dialog_id not in dialog_id_to_dialogue:\n",
    "    raise ValueError(f'Dialogue ID {dialog_id} not found.')\n",
    "\n",
    "  frame = dialog_id_to_dialogue[dialog_id]['turns'][turn_id]['frames'][frame_id]\n",
    "\n",
    "  input_str = frame_predictions['input']['inputs_pretokenized']\n",
    "\n",
    "  # Create a dict(slot -> dict(multiple-choice letter -> value)) for cat slots.\n",
    "  slot_to_option_to_value = _create_categorical_slot_to_value_map(input_str)\n",
    "\n",
    "  if _EVALUATE_INTENT_ACC.value:\n",
    "    # Create a dict(multiple-choice letter -> intent) for intents.\n",
    "    option_to_intent = _create_intent_map(input_str)\n",
    "\n",
    "  # Read and populate all slot value predictions.\n",
    "  # TODO(harrisonlee): Support requested slots.\n",
    "  slot_preds = preds.split('[state]')[1].split('[intent]')[0].strip()\n",
    "  for slot_name, value in re.findall(\n",
    "      rf'(\\w+){_DELIMITER.value}(.*?)(?=\\w+{_DELIMITER.value}|$)', slot_preds):\n",
    "    value = _normalize_value_prediction(slot_name, value,\n",
    "                                        slot_to_option_to_value)\n",
    "\n",
    "    if value:\n",
    "      frame['state']['slot_values'][slot_name] = [value]\n",
    "\n",
    "  # Populate intent prediction.\n",
    "  if _EVALUATE_INTENT_ACC.value and '[intent]' in preds:\n",
    "    # Read and populate intent prediction.\n",
    "    intent_pred = preds.split('[intent]')[1].strip()\n",
    "    frame['state']['active_intent'] = option_to_intent.get(intent_pred, 'NONE')\n",
    "\n",
    "\n",
    "def main(argv: Sequence[str]) -> None:\n",
    "  if len(argv) > 1:\n",
    "    raise app.UsageError('Too many command-line arguments.')\n",
    "\n",
    "  # Load dialogues and flatten into dict(dialogue_id->dialogue).\n",
    "  subdir_to_dialogues = {}\n",
    "  sgd_utils.load_dialogues_to_dict(_DSTC8_DATA_DIR.value, _DATASET_SPLIT.value,\n",
    "                                   subdir_to_dialogues)\n",
    "  dialog_id_to_dialogue = {}\n",
    "  for dialogues in subdir_to_dialogues[_DATASET_SPLIT.value].values():\n",
    "    for dialog in dialogues:\n",
    "      dialog_id_to_dialogue[dialog['dialogue_id']] = dialog\n",
    "\n",
    "  # Erase ground truth state values.\n",
    "  for dial in dialog_id_to_dialogue.values():\n",
    "    for turn in dial['turns']:\n",
    "      for frame in turn['frames']:\n",
    "        if 'state' in frame:\n",
    "          frame['state']['slot_values'] = {}\n",
    "          frame['state']['requested_slots'] = []\n",
    "          frame['state']['active_intent'] = 'NONE'\n",
    "\n",
    "  # Read JSONL predictions.\n",
    "  with tf.io.gfile.GFile(_T5X_PREDICTIONS_JSONL.value, 'r') as predictions_file:\n",
    "    for line in predictions_file:\n",
    "      frame_predictions = json.loads(line)\n",
    "      populate_json_predictions(dialog_id_to_dialogue, frame_predictions)\n",
    "\n",
    "  # Write JSON predictions.\n",
    "  output_dir = _OUTPUT_DIR.value\n",
    "  if not tf.io.gfile.isdir(output_dir):\n",
    "    tf.io.gfile.makedirs(output_dir)\n",
    "\n",
    "  with tf.io.gfile.GFile(os.path.join(output_dir, 'dialogues_all.json'),\n",
    "                         'w') as output_file:\n",
    "    json.dump(\n",
    "        list(dialog_id_to_dialogue.values()),\n",
    "        output_file,\n",
    "        indent=2,\n",
    "        separators=(',', ': '))\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#   flags.mark_flag_as_required('t5x_predictions_jsonl')\n",
    "#   flags.mark_flag_as_required('dstc8_data_dir')\n",
    "#   flags.mark_flag_as_required('output_dir')\n",
    "#   app.run(main)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73e671f5-ad2d-4bff-a640-56092de6eef2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'main' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'main' is not defined"
     ]
    }
   ],
   "source": [
    "main(\"Test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
